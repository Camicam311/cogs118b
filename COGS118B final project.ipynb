{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "data_fp = 'lyrics.csv'\n",
    "df = pd.read_csv(data_fp, engine='python')\n",
    "df = df.drop('Source', axis  = 1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put in word counts\n",
    "df['Word Count'] = df['Lyrics'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>i cant get no satisfaction</td>\n",
       "      <td>the rolling stones</td>\n",
       "      <td>1965</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>the in crowd</td>\n",
       "      <td>ramsey lewis trio</td>\n",
       "      <td>1965</td>\n",
       "      <td>instrumental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>78</td>\n",
       "      <td>love is a hurtin thing</td>\n",
       "      <td>lou rawls</td>\n",
       "      <td>1966</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>80</td>\n",
       "      <td>gloria</td>\n",
       "      <td>shadows of knight</td>\n",
       "      <td>1966</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>98</td>\n",
       "      <td>zorba the greek</td>\n",
       "      <td>herb alpert and the tijuana brass</td>\n",
       "      <td>1966</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                        Song                             Artist  \\\n",
       "2       3  i cant get no satisfaction                 the rolling stones   \n",
       "17     18                the in crowd                  ramsey lewis trio   \n",
       "177    78      love is a hurtin thing                          lou rawls   \n",
       "179    80                      gloria                  shadows of knight   \n",
       "197    98             zorba the greek  herb alpert and the tijuana brass   \n",
       "\n",
       "     Year        Lyrics  Word Count  \n",
       "2    1965                         0  \n",
       "17   1965  instrumental           1  \n",
       "177  1966                         0  \n",
       "179  1966                         0  \n",
       "197  1966                         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove soungs with word count of 0 or 1\n",
    "display(df.loc[df['Word Count'] <= 1].head())\n",
    "df = df[df['Word Count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenize song lyrics, where '\\x02' is START token and '\\x03' is END token\n",
    "df['tokens'] = ('\\x02 ' + df['Lyrics'] + ' \\x03').str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>sam the sham and the pharaohs</td>\n",
       "      <td>1965</td>\n",
       "      <td>sam the sham miscellaneous wooly bully wooly b...</td>\n",
       "      <td>125</td>\n",
       "      <td>[\u0002, sam, the, sham, miscellaneous, wooly, bull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>i cant help myself sugar pie honey bunch</td>\n",
       "      <td>four tops</td>\n",
       "      <td>1965</td>\n",
       "      <td>sugar pie honey bunch you know that i love yo...</td>\n",
       "      <td>204</td>\n",
       "      <td>[\u0002, sugar, pie, honey, bunch, you, know, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>you were on my mind</td>\n",
       "      <td>we five</td>\n",
       "      <td>1965</td>\n",
       "      <td>when i woke up this morning you were on my mi...</td>\n",
       "      <td>152</td>\n",
       "      <td>[\u0002, when, i, woke, up, this, morning, you, wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>youve lost that lovin feelin</td>\n",
       "      <td>the righteous brothers</td>\n",
       "      <td>1965</td>\n",
       "      <td>you never close your eyes anymore when i kiss...</td>\n",
       "      <td>232</td>\n",
       "      <td>[\u0002, you, never, close, your, eyes, anymore, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>downtown</td>\n",
       "      <td>petula clark</td>\n",
       "      <td>1965</td>\n",
       "      <td>when youre alone and life is making you lonel...</td>\n",
       "      <td>239</td>\n",
       "      <td>[\u0002, when, youre, alone, and, life, is, making,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                      Song  \\\n",
       "0     1                               wooly bully   \n",
       "1     2  i cant help myself sugar pie honey bunch   \n",
       "3     4                       you were on my mind   \n",
       "4     5              youve lost that lovin feelin   \n",
       "5     6                                  downtown   \n",
       "\n",
       "                          Artist  Year  \\\n",
       "0  sam the sham and the pharaohs  1965   \n",
       "1                      four tops  1965   \n",
       "3                        we five  1965   \n",
       "4         the righteous brothers  1965   \n",
       "5                   petula clark  1965   \n",
       "\n",
       "                                              Lyrics  Word Count  \\\n",
       "0  sam the sham miscellaneous wooly bully wooly b...         125   \n",
       "1   sugar pie honey bunch you know that i love yo...         204   \n",
       "3   when i woke up this morning you were on my mi...         152   \n",
       "4   you never close your eyes anymore when i kiss...         232   \n",
       "5   when youre alone and life is making you lonel...         239   \n",
       "\n",
       "                                              tokens  \n",
       "0  [\u0002, sam, the, sham, miscellaneous, wooly, bull...  \n",
       "1  [\u0002, sugar, pie, honey, bunch, you, know, that,...  \n",
       "3  [\u0002, when, i, woke, up, this, morning, you, wer...  \n",
       "4  [\u0002, you, never, close, your, eyes, anymore, wh...  \n",
       "5  [\u0002, when, youre, alone, and, life, is, making,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1-gram base model\n",
    "\n",
    "class UnigramLM(object):\n",
    "    \n",
    "    def __init__(self, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a Unigram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using 'train' and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        self.mdl = self.train(tokens)\n",
    "    \n",
    "    def train(self, tokens):\n",
    "        \"\"\"\n",
    "        Trains a unigram language model given a list of tokens.\n",
    "        The output is a series indexed on distinct tokens, and\n",
    "        values giving the probability of a token occuring\n",
    "        in the language.\n",
    "        \"\"\"\n",
    "\n",
    "        return pd.Series(tokens).value_counts(normalize = True)\n",
    "    \n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "        \"\"\"\n",
    "        tokens = ''\n",
    "        \n",
    "        for _ in np.arange(M):\n",
    "            tokens += np.random.choice(self.mdl.index, p = self.mdl.values) + ' '\n",
    "        return tokens.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N-gram model\n",
    "\n",
    "class NGramLM(object):\n",
    "    \n",
    "    def __init__(self, N, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a N-gram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using 'train' and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "\n",
    "        self.N = N\n",
    "        ngrams = self.create_ngrams(tokens)\n",
    "\n",
    "        self.ngrams = ngrams\n",
    "        self.mdl = self.train(ngrams)\n",
    "\n",
    "    def create_ngrams(self, tokens):\n",
    "        \"\"\"\n",
    "        create_ngrams takes in a list of tokens and returns a list of N-grams. \n",
    "        \"\"\"\n",
    "        \n",
    "        ngrams = []\n",
    "        num_preceding = 0\n",
    "        start_dist = 1\n",
    "        for i in np.arange(len(tokens)):\n",
    "\n",
    "            if tokens[i] == '\\x02':\n",
    "                gram = (tokens[i],) * self.N\n",
    "                ngrams.append(gram)\n",
    "                num_preceding = 0\n",
    "                start_dist = 1\n",
    "                continue        \n",
    "\n",
    "            if tokens[i] == '\\x03':\n",
    "                k = 0\n",
    "                while k < self.N:\n",
    "                    gram = ()\n",
    "                    for j in np.arange(self.N - 1 - k, 0, -1):\n",
    "                        gram += (tokens[i - j],)\n",
    "                    gram += ('\\x03',) * (k + 1)\n",
    "                    ngrams.append(gram)\n",
    "                    k += 1\n",
    "            elif num_preceding < self.N - 1:\n",
    "                gram = (tokens[i - start_dist],) * (self.N - 1 - num_preceding)\n",
    "                for j in np.arange(num_preceding, -1, -1):\n",
    "                    gram += (tokens[i - j],)\n",
    "                ngrams.append(gram)\n",
    "                    \n",
    "            else:\n",
    "                gram = ()\n",
    "                for j in np.arange(self.N - 1, -1, -1):\n",
    "                    gram += (tokens[i - j],)\n",
    "                ngrams.append(gram)\n",
    "\n",
    "            num_preceding += 1\n",
    "            start_dist += 1\n",
    "\n",
    "        return ngrams\n",
    "\n",
    "    \n",
    "    def train(self, ngrams):\n",
    "        \"\"\"\n",
    "        Trains a n-gram language model given a list of tokens.\n",
    "        The output is a series indexed on distinct tokens, and\n",
    "        values giving the probability of a token occuring\n",
    "        in the language.\n",
    "        \"\"\"\n",
    "      \n",
    "        # Create ngram counts C(w_1, ..., w_n)\n",
    "        ngram = pd.Series(self.ngrams)\n",
    "        ngram_unigram = UnigramLM(ngram)\n",
    "        \n",
    "        # Create n-1 gram counts C(w_1, ..., w_(n-1))\n",
    "        n1gram = ngram.apply(lambda x: x[:-1])\n",
    "        n1gram_unigram = UnigramLM(n1gram)\n",
    "        \n",
    "        # Create the conditional probabilities\n",
    "        prob = ngram.apply(lambda x: ngram_unigram.mdl[x]) / n1gram.apply(lambda y: n1gram_unigram.mdl[y])\n",
    "        \n",
    "        # Put it all together\n",
    "        return pd.DataFrame({'ngram': ngram, 'n1gram': n1gram, 'prob': prob})\n",
    "\n",
    "    def sample(self, length):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use a helper function to generate sample tokens\n",
    "        def pick_sample(n1gram, M, num_picked):\n",
    "            \n",
    "            if M > 0 and num_picked > self.mdl.shape[0] - (self.N-1)*2:\n",
    "                return '\\x03 ' * M\n",
    "\n",
    "            if n1gram[-1] == '\\x03':\n",
    "                if M > 1:\n",
    "                    return pick_sample(('\\x02',)*(self.N-1), M-1, num_picked + 1)\n",
    "                else:\n",
    "                    return ''\n",
    "\n",
    "            temp = self.mdl.loc[self.mdl['n1gram'] == n1gram].drop_duplicates()\n",
    "            choices = temp['ngram'].apply(lambda x: x[-1]).tolist()\n",
    "            p = temp['prob'].tolist()\n",
    "            if M == 1:\n",
    "                return np.random.choice(choices, p = p) + ' \\x03'\n",
    "\n",
    "            else:\n",
    "                w = np.random.choice(choices, p = p)\n",
    "                if w in set(['\\x02', '\\x03']):\n",
    "                    return pick_sample(n1gram, M, num_picked)\n",
    "                n1gram = (n1gram + (w,))[1:]\n",
    "                return w + ' ' + pick_sample(n1gram, M-1, num_picked+1)\n",
    "        \n",
    "        # Tranform the tokens to strings recursively\n",
    "        sampled_tokens = '\\x02 '\n",
    "        sampled_tokens += pick_sample(('\\x02',)*(self.N-1), length, 0)\n",
    "        return sampled_tokens.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2e863b50860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEICAYAAAB4YQKYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e86385c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Word Count'].plot.hist(title = 'Word Count histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def song_by_year(year, N = 3):\n",
    "    \"\"\"\n",
    "    creates a sample song based on year and number of grams N\n",
    "    If year is out of bounds, throw error\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(year) == int:\n",
    "        if year >= 1965 and year <= 2015:\n",
    "            tokens = list([a for b in df[df['Year'] == year].tokens.tolist() for a in b])\n",
    "            p = df[df['Year'] == year]['Word Count'].value_counts(normalize=True)\n",
    "        else:\n",
    "            raise TypeError(\"Year out of bounds\")        \n",
    "    else:\n",
    "        raise TypeError(\"Invalid Year Input\")\n",
    "        \n",
    "    model = NGramLM(N, tokens)\n",
    "    song_length = np.random.choice(p.index, p = p.values)\n",
    "    \n",
    "    return model.sample(song_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x02 one two three four hey eh forever hey eh foreverits you and it feels like tonight tonight feels like tonight i kissed a girl im pretty sure you count me inive been awake for a model poppin that booty keep bumping titties just bouncin up and wait so close your eyes can do youll probably move right through me on my burner prepaid wireless we pack and deliver like ups trucks already going to hurt when it heals too oh itll all get better in time even though i really love you so sad and lonelyi remember when i believe it and that its good by the collar quick whoever havin problems with their record sales just holler tip if that dont mean im in that thing you know that youve been waitin for him to take you with you its going to hell just pumping that gasall i wanna no is sexy can i hit it like she want it she got it she got me ten feet off the lightsnow if she moves her body like a gangsta cause im trying to keep from goin under baby you believe in your eyes boy you better run for covershe moves her body like a bitch im on your break lights were in the ghetto girl just to get like me have you ever think about is you cant stop i just cant stop i just cant stop it cause she mine and so fine and youre a womanizer babyyou you you dont care whos ya boy in yo life ya thing \\x03'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_by_year(2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def song_by_artist(artist, N = 3):\n",
    "    \"\"\"\n",
    "    creates a sample song based on artist and number of grams N\n",
    "    If no artist not in data, throw error\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(artist) == str:\n",
    "        if artist in set(df['Artist']):\n",
    "            tokens = list([a for b in df[df['Artist'] == artist].tokens.tolist() for a in b])\n",
    "            p = df[df['Artist'] == artist]['Word Count'].value_counts(normalize=True)\n",
    "        else:\n",
    "            raise TypeError(\"Artist not in data\")        \n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Invalid Artist Input\")\n",
    "        \n",
    "    model = NGramLM(N, tokens)\n",
    "    song_length = np.random.choice(p.index, p = p.values)\n",
    "    \n",
    "    return model.sample(song_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x02 we were both young when i saw you standing thereit must have been the way you kissed me fell in love when i first saw you standing there it must have been the way you kissed me fell in love with a fear of fallin wondering why we bother with love if it never lastsi say can you feel this love is difficult but its real dont be afraid well make it out of the city lights on the first date man i didnt kiss him and i know its with mecant you see me again even if its torture dont say i didnt kiss her and i swear im gonna find someone someday who might actually treat me well this is me swallowing my pride standing in a nice dress staring at the sunset babe red lips and rosy cheeks say youll see me hows life tell me when its over if the high was worth the pain got a long list of exlovers theyll tell you to leave cause darling im a nightmare dressed like a daydreamso its gonna be alrightcause the players and you tell me about your dreams i think i know your story like i got home before i said amen asking god if he knows hes all i said amen asking god if he could play it againive heard every album listened to the garden to see you we keep quiet cause were dead if they knew so close your eyes and know shes lucky causehes the reason for the teardrops on my own ill make the moves up as i go back to december turn around and change my own mind i go and i know your story like i got this music in my room its a love story baby just say yesromeo save me ive been feeling so alone i love youooh we called it off i i shake it off heartbreakers gonna break break break break break break break break break break break break break break break break break and the haters gonna hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate baby im just gonna shake shake shake shake shake i shake it off i shake it off i shake it off i shake it off i shake it off i shake \\x03'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_by_artist('taylor swift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
